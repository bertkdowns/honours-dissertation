
\chapter{Architecture Research} \label{sec:architectureresearch}

The literature review also identified a variety of modelling techniques, including Steady-state modelling, Dynamic Modelling, Surrogate Modelling, and Optimisation. 

The Ahuora Digital Twin Platform is currently built to support only steady state modelling. However, to explore the potential for integrating more advanced live data processing techniques, the IDAES Process Systems Engineering Framework was employed as a testbed.

The IDAES framework is a Python library that provides tools for modelling and simulating chemical processes. It is designed to be extensible, allowing for the addition of new modelling techniques.

Using the IDAES framework, experimentation with live data processing techniques was undertaken. This testing aimed to evaluate the feasibility of integrating these advanced techniques into the Ahuora Digital Twin Platform. By leveraging IDAES, the platform can be designed to support the incorporation of more sophisticated modelling techniques in the future.

\section{Research Questions}

The research investigation aimed to answer the following questions:

\begin{itemize}
    \item \textit{RQ1:} How does the Ahuora Simulation Platform need to be modified to support dynamic modelling, surrogate modelling, and optimisation?
    \item \textit{RQ2:} What architecture would best support the integration of live data processing techniques into the Ahuora Digital Twin Platform?
\end{itemize}

\textit{RQ1} focuses on future needs and long-term vision. This is important to help minimise the amount of rework required when implementing new features. \textit{RQ2} focuses on the immediate needs of the project, and is important for developing a pilot implementation.

\section{Dynamic Modelling} 

The IDAES framework was used to develop a dynamic model of a steam tank, with a valve controlling the inlet and outlet pressure and flow rate. A PID controller was used to control the valve opening fraction to regulate the pressure in the tank.

\begin{figure}
    \includegraphics[width=0.9\textwidth]{dynamicmodelling.png}
    \caption{Dynamic Modelling of a Steam Tank}
    \label{fig:dynamicmodelling}
\end{figure}

This provided a simple example of a dynamic system. The inlet and outlet valve and the PID controller were not dynamic models: From a mathematical perspective, this means their properties were fully determined by the inlet and outlet conditions. The only dynamic model was the Steam Tank. From a mathematical perspective, this means that the state of the steam tank was determined not only by the the inlet and outlet conditions, but also by the previous state of the tank, i.e how ``full" the tank is.


\section{Analysis}\label{sec:dynamicmodelling}

\begin{itemize}
    \item The IDAES framework is well-suited to dynamic modelling, as it provides tools for creating and solving differential equations. It can easily model the same system at different time scales.
    \item The Ahuora Simulation Platform requires substantial changes to support dynamic modelling. Rather than storing a single value for each property, it will need to store the state of each property at each time step.
    \item This also necessitates significant UI changes to view the state of the system at different time steps. This could be achieved through some sort of time slider, and graph visualisations of properties over time.
    \item Specifying the initial conditions of the system is more complex, as the user needs to specify the initial state of dynamic properties, such as the initial tank level. Other properties, such as the valve opening fraction, need to be specified as functions of time.
\end{itemize}

\section{Surrogate Modelling}
Surrogate Modelling is the process of creating a simplified model of a complex system. This is usually done using machine learning techniques. This provides a good test case for implementing data-driven modelling techniques within the IDAES framework.

IDAES includes a framework for data-driven modelling called PySMO. This provides utilities for training polynomial, Radial Basis Function (RBF), and Kriging models to approximate the behaviour of a system.

To test the workflow for hybrid modelling, a simple surrogate model is created using PySMO. First, a set of data points is generated by solving a heater model at different pressures, temperatures, and flow rates. 
Then, this data is used to train a surrogate model, which can predict the outlet pressure and enthalpy from the valve based on the inlet conditions. 
This generated data for a steady-state simulation, predicting the outlet pressures and temperatures. 
An RBF network is trained to predict these values from the inlet conditions.
The weights of the trained model are then saved to disk. 

\begin{lstlisting}[language=Python,caption=Using a surrogate model in IDAES,label=lst:heater_surrogate]
model = PysmoSurrogate.load_from_file('pysmo_heater_surrogate.json')
inputs = [self.inlet.pressure, self.inlet.temperature, self.heat_duty, self.inlet.flow_mol ]
outputs = [self.outlet.pressure,self.outlet.temperature,self.outlet_vapor]
self.surrogate = SurrogateBlock(concrete=True)
self.surrogate.build_model(model,input_vars=inputs, output_vars=outputs)
\end{lstlisting}

To use the surrogate model in a flowsheet, the weights of the model are loaded and the structure of the model is recreated as a set of algebraic constraints, relating the input conditions to the predicted output conditions. This can be combined with IDAES's UnitModel class and StateBlocks to create a new unit operation that can be used in a flowsheet.

As shown in Listing \ref{lst:heater_surrogate}, each input and output is linked to a parameter in the unit operation. This works for steady-state models, but dynamic models have a set of parameters, so the surrogate model would need to be able to predict the next time step from the previous time step. This is a much more complex problem, as it would have to be time scale invariant.

\subsection{Analysis}\label{sec:surrogatemodelling}

Surrogate Modelling can be achieved using IDAES's built-in PySMO libraries, or other similar libraries such as OMLT. It is reasonably straightforward to train a surrogate model to represent a non-dynamic unit operation, but dynamic unit operations get significantly more complex - instead of modelling a single value, the surrogate model must be able to model the entire time system. There are some methods of doing this, such as using neural ODEs, Residual Networks, Operator Networks, or some other sort of convolutional network. There is little research into applying these methods in the field of chemical and process simulation, especially in the context of mathematical modelling such as the IDAES framework.

The exact same process for surrogate modelling can also be used to model unit operations from historical data. This is useful when there is no mathematical model of the unit operation, but there is historical data available. This is very useful when considering the application of the Ahuora Digital Twin Platform to existing factories, where the exact mathematical properties of the unit operations are unknown but there is a wealth of historical data available. Online Learning techniques could be used to update the surrogate model in real-time, as new data becomes available. This is a key step in turning a ``simulation" into a ``digital twin", as it allows the model actively adapt to real-world conditions.

Because of the limited functionality of the Ahuora Digital Twin Platform, it is currently beyond the scope of this project to implement a surrogate model. However, the IDAES framework is well-suited to this task, and it is likely that a surrogate model could be implemented in the future.

Additionally, the Ahuora Digital Twin Platform will need a user interface to support creating these different types of models. As surrogate modelling is a complex process, the user interface will need to be able to guide the user through the process of creating a surrogate model from a dataset, and provide feedback on the quality of the model. This will require a significant amount of work, and will likely be a key focus of future development.


\section{Optimisation and Control}

Optimising a system involves adding an objective the model using standard Pyomo utilities, and then solving the model to find the optimal conditions. In the heater model, a cost function is added as a test objective, to find the ideal balance between heat duty and outlet temperature. The model is then solved to find the optimal heat duty that minimises the cost function.

\begin{lstlisting}[language=Python,caption=Optimising the heater model in IDAES,label=lst:optimisation]
def cost_objective(h):
return 3**(h.heat_duty[0]/5000) - (h.outlet.temperature[0]-350) * 33000
m.fs.heater.cost_objective = pyo.Objective(rule=cost_objective, 
                                           sense=pyo.minimize)
\end{lstlisting}

This is shown in Listing \ref{lst:optimisation}. The model must be solved with degrees of freedom, i.e variables that the solver can adjust to find the optimal solution. In this case, the heat duty is the degree of freedom, but there can be multiple degrees of freedom in a model. 
In \Cref{fig:optimisation_dynamics}, a setpoint function for the outlet temperature is added, and optimisation is used to find the heat duty for each timestep such that the resulting outlet temperature best tracks to the setpoint. This has one degree of freedom for each discrete time step that must be optimised: the heat duty at that time step. 
When this technique is used to control a system based on the optimal way to reach a setpoint, it is referred to as Model Predictive Control.
Because the setpoint change is instantaneous, it is unable to perfectly follow the setpoint, but is able to minimise the error on either side of the setpoint through controlling actions. 

\begin{figure}[h]
    \centering
    \includegraphics[width=0.6\textwidth]{research_article/dynamics_optimisation.png}
    \caption{Optimising a dynamic model to follow a setpoint.}
    \label{fig:optimisation_dynamics}
\end{figure}

The optimisation technique used here could be used iteratively for model predictive control, where the model is solved at each time step to find the optimal control action. 


\subsection{Analysis} \label{sec:optimisationcontrol}

Implementing Model Predictive Control in IDAES is relatively straightforward, as long as there is a dynamic model of the system, a cost function, and the optimisation problem is well-posed. The Ahuora Digital Twin Platform does not support optimisation yet, but this will be supported in the future.

In order for model predictive control to be useful, IDAES needs to be paired with a real-time data processing system. The real-time data processing system will need to be able to actuate the suggestions of the MPC simulation in real-time, and then inform the MPC simulation of the system's response. This requires integration with the industry-specific SCADA systems that are used to control factories.

\section{Theoretical Architecture} 

Conventional simulation platforms do not have built-in support for live data processing. Likewise, conventional factory SCADA\footnote{SCADA systems: Supervisory Data Aquisition and Control systems.} systems do not have built-in support for complex simulation. To integrate a simulation platform with live data, a software system must be created that can merge the two systems. This can be considered as an intermediate layer between the simulation platform and the factory SCADA system.


\begin{figure}[h]
    \centering
    \includegraphics[width=0.8\textwidth]{research_article/research_journal_framework_simple.pdf}
    \caption{Theoretical framework of how a Digital Twin can be implementend on top of existing simulators and factory control systems.}
    \label{fig:theoretical_framework}
\end{figure}

The concept of a “Digital Twin” refers to a simulation of something in the physical world, which is kept up to date with a physical system using real-time data \cite{yu2022energy}.
In \Cref{fig:theoretical_framework}, this intermediate layer is what converts the simulation platform, and the data from the factory, into a digital twin. 

By breaking the Digital Twin up into these core components, we are able to make use of existing software systems for live data processing and simulation, and only need to build the components that are unique to the Digital Twin use case. This limits the complexity of the system, and means that implementing a Digital Twin in a factory can be done with minimal disruption to the existing systems.

% These sections should be presenting the arguments that we will make in all the other sections.

\subsection{Modelling and Simulation Platform}


Being able to model and simulate a process is one of the foundational components of a Digital Twin platform. 

Conventionally, simulation platforms are used when designing and planning a factory, and are not used during operation. This makes most conventional simulation platforms unsuitable for use in a Digital Twin, without substantial modification.
In the Ahuora Platform, IDAES-PSE provides the core modelling and simulation capabilities. 
It is built on top of Pyomo, an Algebraic Modelling Language, enabling for flexible model definitions.
This flexibility is key in enabling a Digital Twin platform to be built on top of IDAES. 
Further flexibility is enabled through the Ahuora Platform, which can be modified to support whatever features are required.

% Todo: Give Examples, link to sections that go through the different parts
\subsection{Factory Floor Environment}

In the factory, there are many sensors and control systems that monitor the state of the factory. These systems are often connected to a SCADA system, which is responsible for collecting and displaying this data.
Additionally, there are often data processing systems that are used to store and process this data, as historical data is often used in later analysis to improve performance or make maintenance and upgrade decisions.

There are also automated and manual control systems, which are used to adjust the factory's operation based on the data collected by the SCADA system.
These systems are already implemented in factories, and are critical to the operation of the factory.

% Todo: Give Examples, link to other sections
\subsection{Digital Twin Adapter}

As such, rather than making a new data processing system, it is better that a Digital Twin Platform can be built such that it can be implemented on top of established data processing systems. Likewise, rather than making a new simulation platform, it is better if the framework of an existing simulation platform can be reused or adapted to the digital twin use case.

The concept of a ``Digital Twin Adapter'' is used to define this functionality. It is responsible for converting the data from the factory into a format that the simulation platform can understand, and to provide results from simulations back the factory.


% Todo: give examples, link to other sections
\subsection{Digital Twin State}

Key to the sucessful operation of the the Digital Twin Adapter is the fact that is also has access to the ``Digital Twin State". The Digital Twin State represents an estimate of the current state of the factory, based on the simulation results and the live data. 
This represents the ability of a Digital Twin to "learn" how the physical system behaves, and adjust the inputs to the simulation accordingly.



\section{Discussion} \label{sec:researchconclusions}

The architecture presented generalises the concept of a Digital Twin, enabling software to be built that can be used in a wider variety of factories. However, the exact implementation of the Digital Twin Adapter may need to change depending on the factory's existing systems. Different SCADA systems and data processing systems will have different ways of communicating, and different data will be avaliable depending of the factory. Likewise, different methods of simulation may or may not be avaliable depending on the system. 

The Digital Twin Adapter will need to be built in a way that it can be customised or set up differently depending on the factory. 
% TODO: maybe the research conclusions should be seperated out, or put into the proposed architecture section.
% It makes more sense for the conclusions of this chapter to be about how each of the modelling techniques fit in to the proposed architecture, to argue that my architecture is correct.


The current Ahuora Simulation Platform is split into three main parts:

\begin{itemize}
    \item The Frontend UI, which is written in Typescript/React and runs in the user's web browser. This is responsible for rendering the flowsheet, and allowing the user to interact with the simulation.
    \item The Backend API, which is written in Python/Django and runs on the server. This is responsible for storing the simulation data, orchestrating calls to run the simulation, and returning the results to the user.
    \item The IDAES solving engine, which is written in Python and runs on the server. This is responsible for solving the simulation, and returning the results to the API. It has been seperated out from the API to allow it to be scaled independently.
\end{itemize}

Over time, the Ahuora Simulation platform will be expanded to support dynamic modelling, surrogate modelling, and optimisation.

Additionally, there are also a number of other tools that are used in industry for collecting and processing sensor data. There may be an integrated solution or a number of different tools that are used together, but they can be grouped by their functionality:
\begin{itemize}
    \item Data Collection: These tools are responsible for collecting data from sensors and storing it in a database, as well as cleaning and preprocessing the data. This includes IoT networks and SCADA systems.
    \item Data Processing: These tools are responsible for processing the data to extract useful information. This includes machine learning models, statistical analysis, or other data processing techniques. Generally, these tools will sit within some sort of framework or pipeline, such as Apache Kafka, Flink, or a custom solution.
    \item Data Storage: These tools are responsible for storing the data in a way that is accessible to the other tools. This includes databases, data lakes, or other storage solutions. In Model-Based Systems Engineering, this is often referred to as a Knowledge Base.
\end{itemize}

\begin{figure}
    \centering
    \includegraphics[width=0.9\textwidth]{architecture.png}
    \caption{Anticipated method of implementing the Ahuora Simulation Platform into an industrial system.}
    \label{fig:architecture}
\end{figure}

 Thus, a future requirement of the Ahuora Simulation platform is the connection to these tools to access the sensor data. However, there is a discrepancy in the use cases of the Ahuora Simulation Platform and the standard industrial stack. The Ahuora Simulation Platform is designed with experimentation and analysis in mind, which are usually offline\footnote{Many use cases of the Ahuora Simulation platform include designing new factories or modifications to a factory. These tasks mostly use historical data, and are a distinctly seperate problem from live prediction and control.} tasks performed by expert engineers. The standard industrial stack is designed for real-time prediction and control, which are online tasks performed by operators. Both the engineer and operator workflows will require all the modelling and simulation techniques identified, but the operator's workflow uses a fixed set of models.

\begin{table}[ht]
    \centering
    \caption{Comparison of Engineer's and Operator's Requirements}
    \begin{tabular}{|c|p{0.35\textwidth}|p{0.4\textwidth}|}
        \hline
        \textbf{Requirement} & \textbf{Engineer} & \textbf{Operator} \\
        \hline
        Use Case & Design, Retrofit, & Maintenance, Monitoring, Control \\
        \hline
        Modelling & Creates and modifies multiple models & Fixed set of models, only certain parameters may change\\
        \hline
        Data Usage & Historical data, likely preprocessed or cleaned & Real-time raw data \\
        \hline
        Reliability & It is acceptable if incorrectly configured models don't solve & Model must be correct; Requires 100\% reliability \\
        \hline
    \end{tabular}
    \label{tab:requirements}
\end{table}

Because of the different use cases, while the Ahuora Simulation platform needs to be designed so that it is easy to design and build a model, this functionality is not required in operation. The model could be considered ``frozen'' at this point, where only certain parameters can be changed based on the real-time data. It does not make sense to expose functionality to edit the model to an operator. 



Deploying the a model in production would likely only be done by a trained engineer who manages the plants' SCADA systems.
The deployment would have to be custom for each plant, depending on the SCADA system in use, the sensors available, and the model being used. 
Making a User Interface for this process would be very challenging, and would limit support to only a certain number of protocols. 
Thus, it can be considered that the interface, pipeline, or service between the Ahuora Simulation Platform and the SCADA system is a custom software component. 



%\chapter{Results: Recommended System Architecture} \label{sec:proposed_architecture}

% I'm thinking this could be a bit like a whitepaper, where I outline the requirements for the Ahuora Digital Twin Platform, and how I think it should be implemented.
% then the other sections can go into more depth, to confirm my argument that this is the best way to implement the platform.

% Digital Twin Software needs to suit the use cases of Network Administrators, Chemical Engineers, Process Engineers, and Operators to be useful in industry.
% Steady-State, Dynamic, and Surrogate modelling are all required to support the different use cases.
% A Digital Twin platform needs to integrate with existing SCADA systems and data processing tools to be useful in industry.

% Simulation results need to be avalible within the platform, but this should not replace the company's existing knowledge base/data lake/logging.
% There is no need for Ahuora to develop a new data processing platform, as SCADA systems or things such as kafka/mqtt do this fine.
% It should be easy to switch between design and operation modes, assuming the network administrator has set up the external data processing platform/sources.
% The Ahuora Digital Twin Platform needs to be designed to support these requirements.

% What Hypothesis am I testing here?
% How do I recommend that the above be implemented?


% Todo: Give examples, link to other sections.



